---
- name: create download directory for hadoop
  file:
    path: "{{ hadoop_download_path}}"
    state: directory

- name: download hadoop
  get_url:
    url: "{{ hadoop_url }}"
    dest: "{{ hadoop_download_path }}/hadoop-{{ hadoop_version }}.tgz"

- name: create directory for hadoop
  file:
    path: "{{ hadoop_dir}}"
    state: directory

- name: unarchive hadoop
  unarchive:
    src: "{{ hadoop_download_path }}/hadoop-{{ hadoop_version }}.tgz"
    dest: "{{ hadoop_dir }}"
    copy: no

- name: create hadoop work_dir
  file:
    path: "{{ hadoop_work_dir}}"
    state: directory

# Before 2.3, option 'dest' or 'name' was used instead of 'path'
- name: update bashrc
  blockinfile:
    dest: "/{{ hadoop_user}}/.bashrc"
    block: |
      export JAVA_HOME=/usr/java/default
      export HADOOP_HOME={{hadoop_install_path}}
      export PATH=$PATH:$HADOOP_HOME/bin
      export PATH=$PATH:$HADOOP_HOME/sbin
      export HADOOP_MAPRED_HOME=$HADOOP_HOME
      export HADOOP_COMMON_HOME=$HADOOP_HOME
      export HADOOP_HDFS_HOME=$HADOOP_HOME
      export YARN_HOME=$HADOOP_HOME
      export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
      export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"
      export CLASSPATH=$CLASSPATH:{{ hadoop_install_path}}/lib/*:.
      export HADOOP_OPTS="$HADOOP_OPTS -Djava.security.egd=file:/dev/../dev/urandom"
      export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
      export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
      export HADOOP_OPTS="$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/native"
      export SPARK_HOME={{ spark_dir }}/spark-{{ spark_version }}-bin-hadoop{{ hadoop_spark_version }}
      export SPARK_DIST_CLASSPATH="$SPARK_HOME/jars/*" 
      export CLASSPATH=$CLASSPATH:{{ spark_dir }}/spark-{{ spark_version }}-bin-hadoop{{ hadoop_spark_version }}
      export PATH=$PATH:$SPARK_HOME/bin

- include: start.yml

